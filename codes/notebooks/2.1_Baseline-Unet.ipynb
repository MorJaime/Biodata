{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "IPython.OutputArea.prototype._should_scroll = function(lines) {\n    return false;\n}\n",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "    return false;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Done:\n",
      ">>> Done: Succesfully imported Utils module\n",
      ">>> Done: Succesfully imported Utils module\n"
     ]
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Layer, Conv2D, BatchNormalization, Concatenate, UpSampling2D, MaxPool2D, Input, Dropout, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import initializers\n",
    "from tensorflow.keras import regularizers\n",
    "from keras.utils import np_utils\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "from IPython.display import SVG\n",
    "\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelBinarizer, MultiLabelBinarizer, normalize\n",
    "from sklearn.preprocessing import MinMaxScaler, Normalizer\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from ipywidgets import FloatProgress\n",
    "from IPython.display import display\n",
    "\n",
    "fig_width = 12\n",
    "plt.rcParams[\"font.size\"] = 40\n",
    "plt.rcParams['axes.labelsize'] = 40\n",
    "plt.rcParams['axes.labelweight'] = 'bold'\n",
    "#plt.tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)\n",
    "#plt.rcParams.keys()\n",
    "\n",
    "from codes.utils.HAR_utils import get_activity_index, plot_confusion_matrix, get_Train_Test, timeseries_standardize\n",
    "from codes.models.attention import Attention2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_bird(in_df,shuffle=False,trn='A'):\n",
    "    \n",
    "    in_df.dropna(inplace=True)\n",
    "    birds = list(in_df.drop_duplicates(subset=['animal_tag'],keep = 'first')['animal_tag'])\n",
    "    max_len = 0\n",
    "\n",
    "    for bird in birds:\n",
    "        c_len = len(in_df[in_df['animal_tag'] == bird])\n",
    "        \n",
    "        if c_len > max_len:\n",
    "            print(bird,' : ',c_len,' > ',max_len,' ? ',c_len > max_len)\n",
    "            max_len = c_len\n",
    "        print('bird: ',bird,'lenght: ',c_len)\n",
    "    reqlen = int((int(max_len/512)+1)*512)\n",
    "    print('reqlen: ',reqlen)\n",
    "\n",
    "    features = in_df.columns[2:-2]\n",
    "    X = []\n",
    "    Y = []\n",
    "    times = []\n",
    "    normalizer = Normalizer()\n",
    "\n",
    "    for bird in birds:\n",
    "            x = np.array(in_df[in_df['animal_tag'] == bird][features].values)\n",
    "            #print('x.shape',x.shape)\n",
    "            xz = np.zeros((reqlen-len(x),len(features)))\n",
    "            xs = normalizer.fit_transform(x)\n",
    "            sx = np.concatenate((x,xz))\n",
    "    \n",
    "            y = np.array(in_df[in_df['animal_tag'] == bird]['l_val'].values)\n",
    "            z = np.array([10]*(reqlen-len(y)))\n",
    "            sy = np.concatenate((y,z))\n",
    "    \n",
    "            t = np.array(in_df[in_df['animal_tag'] == bird]['timestamp'].values)\n",
    "            st = np.concatenate((t,z))\n",
    "    \n",
    "            X.append([sx])\n",
    "            Y.append([sy])\n",
    "            times.append(st)\n",
    "\n",
    "    if trn != 1000:\n",
    "        i=0\n",
    "        if shuffle == True:\n",
    "            shuffle == False\n",
    "            print(\"Warning: shuffle cannot be used when selecting a specific bird\")\n",
    "        for bird in birds:\n",
    "            if bird == trn:\n",
    "                selector = i\n",
    "            i=1+i\n",
    "    else:\n",
    "        selector = random.randint(0,len(birds)-1)\n",
    "\n",
    "    if shuffle:\n",
    "        p = list(zip(X,Y))\n",
    "        random.shuffle(p)\n",
    "        X, Y = zip(*p)\n",
    "        X = list(X)\n",
    "        Y = list(Y)\n",
    "\n",
    "    X = np.array(X)\n",
    "    Y = np.array(Y)\n",
    "\n",
    "    times = np.array(times)\n",
    "    print('X(shape): ',X.shape)\n",
    "    print('Y(shape): ',Y.shape)\n",
    "    print('times(shape): ',times.shape)\n",
    "\n",
    "    testX = np.array([X[selector]])\n",
    "    testY = np.array([Y[selector]])\n",
    "    testtimes=times[selector]\n",
    "    trainX = np.delete(X,selector,0)\n",
    "    trainY = np.delete(Y,selector,0)\n",
    "    \n",
    "    return trainX,testX,trainY,testY,testtimes,selector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def down_block(x, filters, kernel_size=(1, 3), padding=\"same\", strides=1, name=\"down_\"):\n",
    "    c = Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\",name=name+\"1\")(x)\n",
    "    c = Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\",name=name+\"2\")(c)\n",
    "    p = MaxPool2D((1, 2),name=name+\"M\")(c)\n",
    "    return c, p\n",
    "\n",
    "def up_block(x, skip, filters, kernel_size=(1, 3), padding=\"same\", strides=1, name=\"up_\"):\n",
    "    us = UpSampling2D((1, 2),name=name+\"U\")(x)\n",
    "    concat = Concatenate()([us, skip])\n",
    "    c = Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\",name=name+\"1\")(concat)\n",
    "    c = Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\",name=name+\"2\")(c)\n",
    "    return c\n",
    "\n",
    "def bottleneck(x, filters, kernel_size=(1, 3), padding=\"same\", strides=1):\n",
    "    c = Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\",name=\"btl1\")(x)\n",
    "    c = Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\",name=\"btl2\")(c)\n",
    "    c = Dropout(0.5)(c)\n",
    "    return c\n",
    "\n",
    "def build_unet_model(height,channels,class_num,f=32):\n",
    "    \n",
    "    inputs = Input((1, height, channels))\n",
    "    \n",
    "    p0 = inputs\n",
    "    c1, p1 = down_block(p0, f, name=\"down_1_\")\n",
    "    c2, p2 = down_block(p1, f*2, name=\"down_2_\")\n",
    "    c3, p3 = down_block(p2, f*4, name=\"down_3_\")\n",
    "    p3 = Dropout(0.5)(p3)\n",
    "    \n",
    "    bn = bottleneck(p3, f*8)\n",
    "    \n",
    "    u1 = up_block(bn, c3, f*4, name=\"up_1_\")\n",
    "    u2 = up_block(u1, c2, f*2, name=\"up_2_\")\n",
    "    u3 = up_block(u2, c1, f, name=\"up_3_\")\n",
    "    \n",
    "    outputs = Dense(class_num, activation = 'softmax')(u3)\n",
    "    model = Model(inputs, outputs)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def ApplyUnet(trainX, trainY, testX, testY,TestTimes, activities, nb_epoch=100, fi=32):\n",
    "    \n",
    "    target_names,indices = get_activity_index(activities)\n",
    "    #print(target_names)\n",
    "    indices.append(len(target_names))\n",
    "    target_names.append('EPadding')\n",
    "    \n",
    "    trainY_b = np_utils.to_categorical(trainY, len(target_names))\n",
    "    testY_b = np_utils.to_categorical(testY, len(target_names))\n",
    "    lb = LabelBinarizer()\n",
    "    \n",
    "    print(indices)\n",
    "    lb.fit(indices)\n",
    "    \n",
    "    model = build_unet_model(trainX.shape[2],trainX.shape[3],len(target_names),f=fi)\n",
    "    model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"acc\"])\n",
    "    model.summary()\n",
    "    \n",
    "    model_checkpoint = keras.callbacks.ModelCheckpoint('biounet-2021_membrane.hdf5', monitor='loss',verbose=1, save_best_only=True)\n",
    "    history = model.fit(trainX, trainY_b, epochs=nb_epoch, validation_split=0.2,callbacks=[model_checkpoint], verbose=0)\n",
    "    \n",
    "    fig, (tr_plt,cm_plt) = plt.subplots(nrows=2, ncols=1, figsize=(6, 6))\n",
    "    \n",
    "    tr_plt.plot(history.history['loss'])\n",
    "    tr_plt.plot(history.history['val_loss'])\n",
    "    tr_plt.set_title('Model loss')\n",
    "    tr_plt.set_ylabel('Loss')\n",
    "    tr_plt.set_xlabel('Epoch')\n",
    "    tr_plt.legend(['loss', 'val_loss'], loc='upper left')\n",
    "\n",
    "      \n",
    "    predict_v = model.predict(testX)\n",
    "    predict_vec = predict_v[0][0]\n",
    "    confidences = np.max(predict_vec, axis=1)\n",
    "    testYY = testY[0][0]\n",
    "    \n",
    "    predict_class = np.argmax(predict_vec, axis=1)\n",
    "    predict = [lb.classes_[x] for x in predict_class]\n",
    "    \n",
    "    print(\"len(testYY)\",len(testYY))\n",
    "    print(\"len(predict)\",len(predict))\n",
    "    \n",
    "    testXX = testX[0][0]\n",
    "    \n",
    "\n",
    "    \n",
    "    for i in range(len(testYY)):\n",
    "        #print(testYY[i])\n",
    "        if testYY[i]==(len(target_names)-1):\n",
    "            testYYY = testYY[:i]\n",
    "            predict1 = predict[:i]\n",
    "            testXXX = testXX[:i]\n",
    "            ttimes = TestTimes[:i]\n",
    "            Confidences = confidences[:i]\n",
    "            print(testYY[i])\n",
    "            print(i)\n",
    "            break\n",
    "\n",
    "    \n",
    "    '''\n",
    "    testYYY = testYY\n",
    "    predict1 = predict\n",
    "    testXXX = testXX\n",
    "    ttimes = TestTimes\n",
    "    Confidences = confidences\n",
    "    '''\n",
    "\n",
    "              \n",
    "    print(\"len(testYYY)\",len(testYYY))\n",
    "    print(\"len(predict1)\",len(predict1))\n",
    "    \n",
    "    result = classification_report(testYYY, predict1, labels=indices, target_names=target_names)\n",
    "    print(result)\n",
    "    testXX=testX\n",
    "    cnf_matrix = confusion_matrix(testYYY, predict1)\n",
    "    plot_confusion_matrix(cnf_matrix, fig, cm_plt, classes=target_names)\n",
    "    fig.tight_layout()\n",
    "    fig.show()\n",
    "    \n",
    "    Sloss = history.history['loss']\n",
    "\n",
    "    return predict1, testYYY, testXXX, Confidences, ttimes, Sloss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run leave_one_bird_out Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leave_one_bird_out_cv(data_df,save_folder,simclass_d, nb_epoch=200, fi=10):\n",
    "\n",
    "    data_df.drop(['year'],axis=1,inplace=True)\n",
    "    data_df = data_df[data_df['label']!='unlabeled']\n",
    "    birds = list(data_df.drop_duplicates(subset=['animal_tag'],keep = 'first')['animal_tag'])\n",
    "\n",
    "    for bird in birds:\n",
    "        trainX,testX,trainY,testY,testtimes,selector = get_train_test_bird(data_df,trn=bird)\n",
    "        trainX , testX = timeseries_standardize(trainX, testX)\n",
    "        predict1, testYYY, testXXX, Confidences, Ttimes, Sloss = ApplyUnet(trainX, trainY, testX, testY, testtimes, simclass_d, nb_epoch=nb_epoch, fi=fi)\n",
    "        test_data_with_conf_pred = pd.DataFrame(data = {'timestamp':Ttimes, 'l_val':testYYY, 'predicted_label':predict1,'confidence':Confidences})\n",
    "        save_fn = 'res_'+bird+'.csv'\n",
    "        save_path = os.path.join(save_folder,save_fn)\n",
    "        test_data_with_conf_pred.to_csv(save_path,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Year data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_csv(r\"G:\\JaimeMorales\\Codes\\omizunagidori\\database\\omizunagidori\\2021\\l_2021_acc.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simclass_df = pd.read_csv(r'G:\\JaimeMorales\\Codes\\omizunagidori\\database\\labels\\O_labels_df.csv')\n",
    "simclass_d = simclass_df['label'].to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_folder = r\"G:\\JaimeMorales\\Codes\\omizunagidori\\database\\results\\baselines\\U-Net\\O_2021\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leave_one_bird_out_cv(data_df,save_folder,simclass_d, nb_epoch=200, fi=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run induvidual test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>animal_tag</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>acc_x</th>\n",
       "      <th>acc_y</th>\n",
       "      <th>acc_z</th>\n",
       "      <th>label</th>\n",
       "      <th>l_val</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LB01</td>\n",
       "      <td>1661544781000</td>\n",
       "      <td>0.011719</td>\n",
       "      <td>-0.105469</td>\n",
       "      <td>0.273438</td>\n",
       "      <td>unlabeled</td>\n",
       "      <td>0</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LB01</td>\n",
       "      <td>1661544781032</td>\n",
       "      <td>0.105469</td>\n",
       "      <td>-0.199219</td>\n",
       "      <td>0.574219</td>\n",
       "      <td>unlabeled</td>\n",
       "      <td>0</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LB01</td>\n",
       "      <td>1661544781064</td>\n",
       "      <td>-0.183594</td>\n",
       "      <td>0.175781</td>\n",
       "      <td>0.066406</td>\n",
       "      <td>unlabeled</td>\n",
       "      <td>0</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LB01</td>\n",
       "      <td>1661544781096</td>\n",
       "      <td>-0.550781</td>\n",
       "      <td>-0.027344</td>\n",
       "      <td>-0.144531</td>\n",
       "      <td>unlabeled</td>\n",
       "      <td>0</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LB01</td>\n",
       "      <td>1661544781129</td>\n",
       "      <td>-0.363281</td>\n",
       "      <td>-0.132813</td>\n",
       "      <td>-0.035156</td>\n",
       "      <td>unlabeled</td>\n",
       "      <td>0</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22942599</th>\n",
       "      <td>LB17</td>\n",
       "      <td>1663492499838</td>\n",
       "      <td>-0.062500</td>\n",
       "      <td>-0.234375</td>\n",
       "      <td>2.093750</td>\n",
       "      <td>unlabeled</td>\n",
       "      <td>0</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22942600</th>\n",
       "      <td>LB17</td>\n",
       "      <td>1663492499870</td>\n",
       "      <td>-0.433594</td>\n",
       "      <td>-0.074219</td>\n",
       "      <td>2.031250</td>\n",
       "      <td>unlabeled</td>\n",
       "      <td>0</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22942601</th>\n",
       "      <td>LB17</td>\n",
       "      <td>1663492499903</td>\n",
       "      <td>-0.304688</td>\n",
       "      <td>-0.320313</td>\n",
       "      <td>1.878906</td>\n",
       "      <td>unlabeled</td>\n",
       "      <td>0</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22942602</th>\n",
       "      <td>LB17</td>\n",
       "      <td>1663492499935</td>\n",
       "      <td>-0.062500</td>\n",
       "      <td>-0.554688</td>\n",
       "      <td>1.621094</td>\n",
       "      <td>unlabeled</td>\n",
       "      <td>0</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22942603</th>\n",
       "      <td>LB17</td>\n",
       "      <td>1663492499967</td>\n",
       "      <td>-0.089844</td>\n",
       "      <td>-0.382813</td>\n",
       "      <td>1.113281</td>\n",
       "      <td>unlabeled</td>\n",
       "      <td>0</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22942604 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         animal_tag      timestamp     acc_x     acc_y     acc_z      label  \\\n",
       "0              LB01  1661544781000  0.011719 -0.105469  0.273438  unlabeled   \n",
       "1              LB01  1661544781032  0.105469 -0.199219  0.574219  unlabeled   \n",
       "2              LB01  1661544781064 -0.183594  0.175781  0.066406  unlabeled   \n",
       "3              LB01  1661544781096 -0.550781 -0.027344 -0.144531  unlabeled   \n",
       "4              LB01  1661544781129 -0.363281 -0.132813 -0.035156  unlabeled   \n",
       "...             ...            ...       ...       ...       ...        ...   \n",
       "22942599       LB17  1663492499838 -0.062500 -0.234375  2.093750  unlabeled   \n",
       "22942600       LB17  1663492499870 -0.433594 -0.074219  2.031250  unlabeled   \n",
       "22942601       LB17  1663492499903 -0.304688 -0.320313  1.878906  unlabeled   \n",
       "22942602       LB17  1663492499935 -0.062500 -0.554688  1.621094  unlabeled   \n",
       "22942603       LB17  1663492499967 -0.089844 -0.382813  1.113281  unlabeled   \n",
       "\n",
       "          l_val  year  \n",
       "0             0  2022  \n",
       "1             0  2022  \n",
       "2             0  2022  \n",
       "3             0  2022  \n",
       "4             0  2022  \n",
       "...         ...   ...  \n",
       "22942599      0  2022  \n",
       "22942600      0  2022  \n",
       "22942601      0  2022  \n",
       "22942602      0  2022  \n",
       "22942603      0  2022  \n",
       "\n",
       "[22942604 rows x 8 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = pd.read_csv(r\"G:\\JaimeMorales\\Codes\\omizunagidori\\database\\omizunagidori\\2022\\l_2022_acc.csv\")\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.drop(['year'],axis=1,inplace=True)\n",
    "data_df = data_df[data_df['label']!='unlabeled']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LB01',\n",
       " 'LB02',\n",
       " 'LB03',\n",
       " 'LB04',\n",
       " 'LB05',\n",
       " 'LB08',\n",
       " 'LB09',\n",
       " 'LB11',\n",
       " 'LB13',\n",
       " 'LB14',\n",
       " 'LB15',\n",
       " 'LB17']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "birds = list(data_df.drop_duplicates(subset=['animal_tag'],keep = 'first')['animal_tag'])\n",
    "birds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_df = data_df\n",
    "save_folder = r\"G:\\JaimeMorales\\Codes\\omizunagidori\\database\\results\\baselines\\U-Net\\O_2021\"\n",
    "simclass_df = pd.read_csv(r'G:\\JaimeMorales\\Codes\\omizunagidori\\database\\labels\\O_labels_df.csv')\n",
    "simclass_d = simclass_df['label'].to_dict()\n",
    "nb_epoch=200\n",
    "fi=10\n",
    "trn = 'LB02'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divide train Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX,testX,trainY,testY,testtimes,selector = get_train_test_bird(data_df,trn='LB0x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(selector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = data_df[data_df['animal_tag']==birds[selector]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('trainX(shape): ',trainX.shape)\n",
    "print('trainY(shape): ',trainY.shape)\n",
    "\n",
    "print('testX(shape): ',testX.shape)\n",
    "print('testY(shape): ',testY.shape)\n",
    "print('testtimes(len): ',len(testtimes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX , testX = timeseries_standardize(trainX, testX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simclass_df = pd.read_csv(r'G:\\JaimeMorales\\Codes\\omizunagidori\\database\\labels\\O_labels_df.csv')\n",
    "simclass_d = simclass_df['label'].to_dict()\n",
    "#simclass_d[len('simclass_d')]='pad_class'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simclass_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "predict1, testYYY, testXXX, Confidences, Ttimes, Sloss = ApplyUnet(trainX, trainY, testX, testY, testtimes, simclass_d, nb_epoch=200, fi=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_with_conf_pred = pd.DataFrame(data = {'time':Ttimes, 'l_val':testYYY, 'predicted_label':predict1,'confidence':Confidences})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_folder = r'G:\\JaimeMorales\\Codes\\Biodata\\database\\results'\n",
    "save_fn = 'res_'+birds[selector]+'.csv'\n",
    "save_path = os.path.join(save_folder,save_fn)\n",
    "save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_with_conf_pred.to_csv(save_path,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tttimes = range(len(predict1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labels,indices = get_activity_index(simclass_d)\n",
    "indices.append(11)\n",
    "labels.append('EPadding')\n",
    "figs = plt.figure('result',figsize=(10, 4))\n",
    "axs = plt.subplot(111)\n",
    "axs.plot(tttimes, predict1, color='r')\n",
    "axs.plot(tttimes, testYYY, color='g')\n",
    "axs.set_ylabel('Activity label')\n",
    "axs.set_yticks(indices)\n",
    "axs.set_yticklabels(labels)\n",
    "figs.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

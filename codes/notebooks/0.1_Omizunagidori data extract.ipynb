{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import random\n",
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "import csv\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "#import tensorflow_probability as tfp\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import backend as K\n",
    "from keras.utils import np_utils\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.callbacks import EarlyStopping\n",
    "from IPython.display import SVG\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelBinarizer, MultiLabelBinarizer, normalize\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from ipywidgets import FloatProgress\n",
    "from IPython.display import display\n",
    "\n",
    "fig_width = 12\n",
    "plt.rcParams[\"font.size\"] = 40\n",
    "plt.rcParams['axes.labelsize'] = 40\n",
    "plt.rcParams['axes.labelweight'] = 'bold'\n",
    "#plt.tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)\n",
    "#plt.rcParams.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 14770526856357074960\n",
       " xla_global_id: -1,\n",
       " name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 6922698752\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 9113417002716399420\n",
       " physical_device_desc: \"device: 0, name: NVIDIA GeForce GTX 1080, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
       " xla_global_id: 416903419]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'codes'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mg:\\JaimeMorales\\Codes\\Biodata\\codes\\notebooks\\0.1_Omizunagidori data extract.ipynb Cell 3\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/JaimeMorales/Codes/Biodata/codes/notebooks/0.1_Omizunagidori%20data%20extract.ipynb#W2sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m sys\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mappend(\u001b[39m'\u001b[39m\u001b[39m../codes\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/g%3A/JaimeMorales/Codes/Biodata/codes/notebooks/0.1_Omizunagidori%20data%20extract.ipynb#W2sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcodes\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mload_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m num_labels, time_change, setup_dir, find_xml_filenames, find_csv_filenames\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'codes'"
     ]
    }
   ],
   "source": [
    "sys.path.append('../codes')\n",
    "from codes.load_utils import num_labels, time_change, setup_dir, find_xml_filenames, find_csv_filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "omizu_path = r\"G:\\JaimeMorales\\Codes\\omizunagidori\\export\\Omizunagidori\"\n",
    "umineko_path = r\"G:\\JaimeMorales\\Codes\\omizunagidori\\export\\Umineko\"\n",
    "database_path = r\"G:\\JaimeMorales\\Codes\\omizunagidori\\database\"\n",
    "database_l_path = r\"G:\\JaimeMorales\\Codes\\omizunagidori\\database\\labels\"\n",
    "database_o_acc_path = r\"G:\\JaimeMorales\\Codes\\omizunagidori\\database\\omizunagidori\"\n",
    "database_u_acc_path = r\"G:\\JaimeMorales\\Codes\\omizunagidori\\database\\umineko\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_labels(paths, label_wr_dir = r'G:\\JaimeMorales\\Codes\\biodata\\database\\labels', fn_end = 17):\n",
    "    \n",
    "    for path in paths:\n",
    "        label_path = path\n",
    "        label_dir_p, label_fn = os.path.split(label_path)\n",
    "        wr_fn = label_fn[:fn_end]\n",
    "        tree = ET.parse(label_path)\n",
    "        root = tree.getroot()\n",
    "        filename = os.path.join(label_wr_dir,wr_fn+'_labels.csv')\n",
    "        \n",
    "        with open(filename,\"w\") as f:            \n",
    "            csv_writer = csv.writer(f)\n",
    "            header = [\"event_type\",\"start\", \"end\"]\n",
    "            csv_writer.writerow(header)\n",
    "            for labellist in root.iter(\"labellist\"):\n",
    "                timestampStart = labellist[1].text\n",
    "                timestampStart = timestampStart.replace('-','')\n",
    "                timestampStart = timestampStart.replace('T',' ')      \n",
    "                timestampStart = timestampStart.replace('Z','')\n",
    "                timestampEnd = labellist[2].text\n",
    "                timestampEnd = timestampEnd.replace('-','')\n",
    "                timestampEnd = timestampEnd.replace('T',' ')\n",
    "                timestampEnd = timestampEnd.replace('Z','')\n",
    "\n",
    "                row = [labellist[0].text, labellist[1].text, labellist[2].text]\n",
    "                row = [labellist[0].text,timestampStart,timestampEnd]\n",
    "                csv_writer.writerow(row)\n",
    "            \n",
    "        print('created labels for >>> ',filename)\n",
    "        \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create label files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_path_o = os.path.join(omizu_path,'labels')\n",
    "label_paths_o = find_xml_filenames(label_path_o)\n",
    "make_labels(label_paths_o, os.path.join(database_l_path,'omizunagidori'), fn_end = 17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_path_u = os.path.join(umineko_path,'labels')\n",
    "label_paths_u = find_xml_filenames(label_path_u)\n",
    "make_labels(label_paths_u, os.path.join(database_l_path,'umineko'), fn_end = 11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separate sensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Omizunagidori filenames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2018 file names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "O_Y18_save_folder = os.path.join(database_o_acc_path,'2018')\n",
    "O_Y18_raw_path = os.path.join(omizu_path,'raw')\n",
    "O_Y18_raw_paths = find_csv_filenames(O_Y18_raw_path, suffix = \".csv\", year = '2018')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2019 file names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "O_Y19_save_folder = os.path.join(database_o_acc_path,'2019')\n",
    "O_Y19_raw_path = os.path.join(omizu_path,'raw')\n",
    "O_Y19_raw_paths = find_csv_filenames(O_Y19_raw_path, suffix = \".csv\", year = '2019')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2020 file names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "O_Y20_save_folder = os.path.join(database_o_acc_path,'2020')\n",
    "O_Y20_raw_path = os.path.join(omizu_path,'raw')\n",
    "O_Y20_raw_paths = find_csv_filenames(O_Y20_raw_path, suffix = \".csv\", year = '2020')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2021 file names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "O_Y21_save_folder = os.path.join(database_o_acc_path,'2021')\n",
    "O_Y21_raw_path = os.path.join(omizu_path,'raw')\n",
    "O_Y21_raw_paths = find_csv_filenames(O_Y21_raw_path, suffix = \".csv\", year = '2021')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2022 file names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "O_Y22_save_folder = os.path.join(database_o_acc_path,'2022')\n",
    "O_Y22_raw_path = os.path.join(omizu_path,'raw')\n",
    "O_Y22_raw_paths = find_csv_filenames(O_Y22_raw_path, suffix = \".csv\", year = '2022')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ALL Omizunagidori files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "O_all_save_folder = [O_Y18_save_folder, O_Y19_save_folder, O_Y20_save_folder, O_Y21_save_folder, O_Y22_save_folder]\n",
    "O_all_raw_paths = [O_Y18_raw_paths, O_Y19_raw_paths, O_Y20_raw_paths, O_Y21_raw_paths, O_Y22_raw_paths]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Umineko filenames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2018 file names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U_Y18_save_folder = os.path.join(database_u_acc_path,'2018')\n",
    "U_Y18_raw_path = os.path.join(umineko_path,'raw')\n",
    "U_Y18_raw_paths = find_csv_filenames(U_Y18_raw_path, suffix = \".csv\", year = '2018')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2019 file names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U_Y19_save_folder = os.path.join(database_u_acc_path,'2019')\n",
    "U_Y19_raw_path = os.path.join(umineko_path,'raw')\n",
    "U_Y19_raw_paths = find_csv_filenames(U_Y19_raw_path, suffix = \".csv\", year = '2019')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2022 file names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U_Y22_save_folder = os.path.join(database_u_acc_path,'2022')\n",
    "U_Y22_raw_path = os.path.join(umineko_path,'raw')\n",
    "U_Y22_raw_paths = find_csv_filenames(U_Y22_raw_path, suffix = \".csv\", year = '2022')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All umineko files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U_all_save_folder = [U_Y18_save_folder, U_Y19_save_folder, U_Y22_save_folder]\n",
    "U_all_raw_paths = [U_Y18_raw_paths, U_Y19_raw_paths, U_Y22_raw_paths]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sensor specific dataframe creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_by_sensor(filename, save_folder, sensor='acc', time_format=\"%Y%m%d_%H:%M:%S.%f\"):\n",
    "    data = pd.read_csv(filename, parse_dates=[\"timestamp\"])\n",
    "    data[\"timestamp\"] = pd.to_datetime(data[\"timestamp\"],format=time_format)\n",
    "    \n",
    "    #data['label'] = np.where(data['timestamp']=='NaN', 'unknown', data['label'])\n",
    "    data.fillna('unlabeled',inplace=True)\n",
    "    \n",
    "    if sensor == 'acc':\n",
    "        new_df = data.drop(['logger_id', 'latitude', 'longitude', 'gps_status', 'gyro_x', 'gyro_y', 'gyro_z', 'mag_x', 'mag_y', 'mag_z', 'illumination', 'pressure', 'temperature','activity_class'],axis=1)\n",
    "    else:\n",
    "        new_df = data\n",
    "        \n",
    "    name = filename[-11:-4]\n",
    "    name = name.replace('_','')\n",
    "    name = name.replace('00','')\n",
    "    save_name = os.path.join(save_folder,'data_w_timestamps',name+'_acc.csv')\n",
    "    new_df.to_csv(save_name,index=False)\n",
    "    print('Saved to: ', save_name) \n",
    "    \n",
    "    #data_df = pd.read_csv(save_name, parse_dates=[\"timestamp\"])\n",
    "    data_df = new_df\n",
    "    #l = []\n",
    "    #for i in range(len(data)):\n",
    "    #    l.append(data_df['timestamp'][i].replace('+00:00',''))\n",
    "    #data_df['timestamp'] = l\n",
    "    #data_df['timestamp'][0] = data_df['timestamp'][0]+'.000000'\n",
    "    \n",
    "    #data_df = pd.to_datetime(data_df[\"timestamp\"],format=time_format)\n",
    "    \n",
    "    data_df = time_change(data_df)\n",
    "    \n",
    "    #data_df.to_csv(os.path.join(save_folder,name+'t_acc.csv'),index=False)\n",
    "    return data_df\n",
    "    \n",
    "def join_by_year(read_dir):\n",
    "\n",
    "    all_bird_lst = []\n",
    "    for file in os.listdir(os.path.join(read_dir,'data_w_timestamps')):\n",
    "        if file.endswith(\".csv\"):\n",
    "            path = os.path.join(read_dir, 'data_w_timestamps', file)\n",
    "            print(path)\n",
    "            df = pd.read_csv(path,parse_dates=[\"timestamp\"])\n",
    "            all_bird_lst.append(df)\n",
    "            #all_bird_df = all_bird_df._append(df, ignore_index=True)\n",
    "            #all_bird_df = pd.concat([all_bird_df,df])\n",
    "\n",
    "    all_bird_df = pd.concat(all_bird_lst)\n",
    "\n",
    "    birds = list(all_bird_df.drop_duplicates(subset=['animal_tag'],keep = 'first')['animal_tag'])\n",
    "    print(birds)\n",
    "    \n",
    "    all_bird_df.to_csv(os.path.join(read_dir, 'all_bird_df.csv'),index=False)\n",
    "\n",
    "    #print(all_bird_df)\n",
    "\n",
    "    #all_bird_df.drop(['activity_class'],axis = 1,inplace = True)\n",
    "    #all_bird_df['label'] = np.where(all_bird_df['timestamp']=='NaN', 'unknown', all_bird_df['label'])\n",
    "    #all_bird_df.fillna('unknown',inplace=True)\n",
    "    all_bird_df.dropna(inplace = True)\n",
    "    all_bird_df.reset_index(inplace = True)\n",
    "    all_bird_df.drop(['index'],axis = 1,inplace = True)\n",
    "    all_bird_df.to_csv(os.path.join(read_dir, 'all_bird_df_Y' + os.path.split(read_dir)[-1] +'_WL.csv'),index=False)\n",
    "    \n",
    "    labels_df = all_bird_df.drop_duplicates(subset=['label'],keep = 'first')['label']\n",
    "    labels_l = list(labels_df)\n",
    "    print('labels' + os.path.split(read_dir)[-1]+':')\n",
    "    print(labels_l)\n",
    "    labels_df.to_csv(os.path.join(read_dir, 'label_df_Y' + os.path.split(read_dir)[-1] +'.csv'),index=False)\n",
    "    \n",
    "    return all_bird_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create acc files - OMIZUNAGIDORI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_acc_files(all_raw_paths,all_save_folder,bird_n):\n",
    "\n",
    "    all_bird_Y_df_l = []\n",
    "    year_df_t_l = []\n",
    "\n",
    "    for i in range(len(all_save_folder)):\n",
    "        bird_df_t_l =[]\n",
    "        for raw_path in all_raw_paths[i]:\n",
    "            print('Acc sensor df from: ', raw_path)\n",
    "            bird_acc_df = separate_by_sensor(raw_path,all_save_folder[i])\n",
    "            bird_df_t_l.append(bird_acc_df)\n",
    "        year_df_t = pd.concat(bird_df_t_l)\n",
    "        year_df_t_l.append(year_df_t)\n",
    "        all_bird = join_by_year(all_save_folder[i])\n",
    "        print('Joined all sensors for: ', all_save_folder[i])\n",
    "        all_bird_Y_df_l.append(all_bird)\n",
    "\n",
    "### Join all birds by year with Unix time\n",
    "\n",
    "    all_t_df = pd.concat(year_df_t_l)\n",
    "    #all_t_df.drop(['activity_class'], axis=1, inplace=True)\n",
    "    all_t_df.dropna(inplace=True)\n",
    "    all_t_df.reset_index(inplace = True)\n",
    "    all_t_df.drop(['index'],axis = 1,inplace = True)\n",
    "    #print('timechange dataframe: ')\n",
    "    #print(all_t_df)\n",
    "\n",
    "    all_df = pd.concat(all_bird_Y_df_l)\n",
    "    labels_df = pd.DataFrame(all_df.drop_duplicates(subset=['label'],keep = 'first')['label'])\n",
    "    labels_df.reset_index(inplace=True)\n",
    "    labels_df.drop(['index'],axis=1,inplace=True)\n",
    "\n",
    "    if bird_n=='omizunagidori':\n",
    "        all_t_df.to_csv(os.path.join(database_o_acc_path,'Omizu_all_t_df.csv'), index = False)\n",
    "        labels_df.to_csv(os.path.join(database_l_path,'O_labels_df.csv'),index = False)\n",
    "    elif bird_n=='umineko':\n",
    "        all_t_df.to_csv(os.path.join(database_u_acc_path,'Umineko_all_t_df.csv'), index = False)\n",
    "        labels_df.to_csv(os.path.join(database_l_path,'U_labels_df.csv'),index = False)\n",
    "\n",
    "### Join all birds by year with timestamp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "O_all_bird_Y_df_l = []\n",
    "year_df_t_l = []\n",
    "\n",
    "for i in range(len(O_all_save_folder)):\n",
    "    bird_df_t_l =[]\n",
    "    for raw_path in O_all_raw_paths[i]:\n",
    "        print('Acc sensor df from: ', raw_path)\n",
    "        bird_acc_df = separate_by_sensor(raw_path,O_all_save_folder[i])\n",
    "        bird_df_t_l.append(bird_acc_df)\n",
    "    year_df_t = pd.concat(bird_df_t_l)\n",
    "    year_df_t_l.append(year_df_t)\n",
    "    all_bird = join_by_year(O_all_save_folder[i])\n",
    "    print('Joined all sensors for: ', O_all_save_folder[i])\n",
    "    O_all_bird_Y_df_l.append(all_bird)\n",
    "\n",
    "### Join all birds by year with Unix time\n",
    "\n",
    "Omizu_all_t_df = pd.concat(year_df_t_l)\n",
    "#Omizu_all_t_df.drop(['activity_class'], axis=1, inplace=True)\n",
    "Omizu_all_t_df.dropna(inplace=True)\n",
    "Omizu_all_t_df.reset_index(inplace = True)\n",
    "Omizu_all_t_df.drop(['index'],axis = 1,inplace = True)\n",
    "#print('timechange dataframe: ')\n",
    "#print(Omizu_all_t_df)\n",
    "Omizu_all_t_df.to_csv(os.path.join(database_o_acc_path,'Omizu_all_t_df.csv'), index = False)\n",
    "\n",
    "### Join all birds by year with timestamp\n",
    "\n",
    "Omizu_all_df = pd.concat(O_all_bird_Y_df_l)\n",
    "O_labels_df = pd.DataFrame(Omizu_all_df.drop_duplicates(subset=['label'],keep = 'first')['label'])\n",
    "O_labels_df.reset_index(inplace=True)\n",
    "O_labels_df.drop(['index'],axis=1,inplace=True)\n",
    "O_labels_df.to_csv(os.path.join(database_l_path,'O_labels_df.csv'),index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create acc files - UMINEKO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U_all_bird_Y_df_l = []\n",
    "year_df_t_l = []\n",
    "\n",
    "for i in range(len(U_all_save_folder)):\n",
    "    bird_df_t_l =[]\n",
    "    for raw_path in U_all_raw_paths[i]:\n",
    "        print('Acc sensor df from: ', raw_path)\n",
    "        print('Saved to: ', U_all_save_folder[i]) \n",
    "        bird_acc_df = separate_by_sensor(raw_path,U_all_save_folder[i])\n",
    "        bird_df_t_l.append(bird_acc_df)\n",
    "    year_df_t = pd.concat(bird_df_t_l)\n",
    "    year_df_t_l.append(year_df_t)\n",
    "    all_bird = join_by_year(U_all_save_folder[i])\n",
    "    U_all_bird_Y_df_l.append(all_bird)\n",
    "\n",
    "### Join all birds by year with Unix time\n",
    "\n",
    "Umineko_all_t_df = pd.concat(year_df_t_l)\n",
    "#Umineko_all_t_df.drop(['activity_class'], axis=1, inplace=True)\n",
    "Umineko_all_t_df.dropna(inplace=True)\n",
    "Umineko_all_t_df.reset_index(inplace = True)\n",
    "Umineko_all_t_df.drop(['index'],axis = 1,inplace = True)\n",
    "#print('timechange dataframe: ')\n",
    "#print(Umineko_all_t_df)\n",
    "Umineko_all_t_df.to_csv(os.path.join(database_u_acc_path,'Umineko_all_t_df.csv'), index = False)\n",
    "\n",
    "### Join all birds by year with timestamp\n",
    "\n",
    "umineko_all_df = pd.concat(U_all_bird_Y_df_l)\n",
    "U_labels_df = pd.DataFrame(umineko_all_df.drop_duplicates(subset=['label'],keep = 'first')['label'])\n",
    "U_labels_df.reset_index(inplace=True)\n",
    "U_labels_df.drop(['index'],axis=1,inplace=True)\n",
    "U_labels_df.to_csv(os.path.join(database_l_path,'U_labels_df.csv'),index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assign labels, separate years, separate birds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Year times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_years(acc_df,write_folder,year_times):\n",
    "    \n",
    "    new_df = acc_df\n",
    "    new_df['year']='0'\n",
    "    years = list(year_times.keys())\n",
    "\n",
    "    for year in years:\n",
    "        print(year_times[year][0])\n",
    "        year_df = new_df[new_df['timestamp']>year_times[year][0]]\n",
    "        year_df = year_df[year_df['timestamp']<year_times[year][1]]\n",
    "        new_df['year'] = np.where(new_df['timestamp'].between(year_times[year][0],year_times[year][1]), year, new_df['year'])\n",
    "        year_df = new_df[new_df['year']==year]\n",
    "        year_df.to_csv(os.path.join(write_folder,year,'l_'+year+'_acc.csv'),index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_birds(read_folder,year_times):\n",
    "    \n",
    "    years = list(year_times.keys())\n",
    "\n",
    "    for year in years:\n",
    "        year_df = pd.read_csv(os.path.join(read_folder,year,'l_'+year+'_acc.csv'))\n",
    "        birds_df = pd.DataFrame(year_df.drop_duplicates(subset=['animal_tag'],keep = 'first')['animal_tag'])\n",
    "        birds = list(birds_df['animal_tag'])\n",
    "        print('year: ',year)\n",
    "        for bird in birds:\n",
    "            print('bird: '+bird)\n",
    "            new_df = year_df[year_df['animal_tag']==bird]\n",
    "            new_df.to_csv(os.path.join(read_folder,year,'labeled',bird+'_l_acc.csv'),index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "omizu_labels_all_df = pd.read_csv(os.path.join(database_l_path,'O_labels_df.csv'))\n",
    "omizu_l_dict = omizu_labels_all_df['label'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "umineko_labels_all_df = pd.read_csv(os.path.join(database_l_path,'U_labels_df.csv'))\n",
    "umineko_l_dict = umineko_labels_all_df['label'].to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Omizunagidori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o_year_times = {'2018':[1514768460000,1546304460000],'2019':[1546304460000,1577840460000],'2020':[1577840460000,1609462860000],'2021':[1609462860000,1640998860000],'2022':[1640998860000,1672534860000]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Omizu_all_t_df = pd.read_csv(os.path.join(database_o_acc_path,'omizu_all_t_df.csv'))\n",
    "omizu_lab_all_df = num_labels(Omizu_all_t_df,omizu_labels_all_df)\n",
    "divide_years(omizu_lab_all_df,database_o_acc_path,o_year_times)\n",
    "divide_birds(database_o_acc_path,o_year_times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Umineko"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_year_times = {'2018':[1514768460000,1546304460000],'2019':[1546304460000,1577840460000],'2022':[1640998860000,1672534860000]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Umineko_all_t_df = pd.read_csv(os.path.join(database_u_acc_path,'umineko_all_t_df.csv'))\n",
    "umineko_lab_all_df = num_labels(Umineko_all_t_df,umineko_labels_all_df)\n",
    "divide_years(umineko_lab_all_df,database_u_acc_path,u_year_times)\n",
    "divide_birds(database_u_acc_path,u_year_times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# verifylabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = '2022'\n",
    "o_labels_2022 = pd.read_csv(os.path.join(database_l_path,'omizunagidori','Omizunagidori'+year+'_labels.csv'),parse_dates=['start','end'])\n",
    "t_labels = time_change(o_labels_2022,column='start')\n",
    "changed_t_labels = time_change(t_labels,column='end')\n",
    "changed_t_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.path.join(database_o_acc_path,year,'l_'+year+'_acc.csv'))\n",
    "data_l_df = pd.read_csv(os.path.join(database_o_acc_path,year,'l_'+year+'_acc.csv'))\n",
    "data_l_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vizualize transformed data\n",
    "## Load DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_path = r\"G:\\JaimeMorales\\Codes\\omizunagidori\\database\\omizunagidori\\2022\\l_2022_acc.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_df = pd.read_csv(viz_path,parse_dates=[\"timestamp\"])\n",
    "viz_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bird_df = viz_df[viz_df['animal_tag']=='LB01']\n",
    "bird_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bird_l_df = bird_df[bird_df['label']=='unknown']\n",
    "bird_l_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_df = bird_l_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_two_data_segments(data, start_idx, lenght, label_name = \"l_val\"):\n",
    "    \n",
    "    fig = plt.figure(num=1, figsize=(50,30), dpi=300)\n",
    "    axL = fig.add_axes([0, 0, 1, 1])\n",
    "    plot_one_data_segment(axL, data, start_idx, lenght, label_name = label_name)\n",
    "    fig.savefig(r\"G:\\JaimeMorales\\Codes\\omizunagidori\\figures\\timeseries.svg\", format = 'svg', dpi=500, bbox_inches = 'tight')\n",
    "    fig.tight_layout()\n",
    "    fig.show()\n",
    "    \n",
    "def plot_one_data_segment(ax, data, start_idx, length, label_name = \"label\"):\n",
    "    if start_idx + length > len(data) - 1:\n",
    "        start_idx = len(data) - 1 - length\n",
    "    if start_idx < 0:\n",
    "        start_idx = 0\n",
    "    ax.plot(data[\"timestamp\"][start_idx:start_idx + length], data['acc_x'][start_idx:start_idx + length], '-' , color = 'red', linewidth=12)\n",
    "    ax.plot(data[\"timestamp\"][start_idx:start_idx + length], data['acc_y'][start_idx:start_idx + length], '-' , color = 'green', linewidth=12)\n",
    "    ax.plot(data[\"timestamp\"][start_idx:start_idx + length], data['acc_z'][start_idx:start_idx + length], '-' , color = 'blue', linewidth=12)\n",
    "    ax.tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)\n",
    "    ax.tick_params(axis='y', which='both', bottom=False, top=False, labelbottom=False)\n",
    "    #ax.set_xlabel(\"time [s]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_two_data_segments(viz_df, 12000, 2000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
